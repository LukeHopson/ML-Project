{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVZss8Vp0cWi",
        "outputId": "2cfdb6d2-c495-4b1d-c59f-a12137b44432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   person_age  person_income  person_emp_exp  loan_amnt  loan_int_rate  \\\n",
            "0        22.0        71948.0               0    35000.0          16.02   \n",
            "1        21.0        12282.0               0     1000.0          11.14   \n",
            "2        25.0        12438.0               3     5500.0          12.87   \n",
            "3        23.0        79753.0               0    35000.0          15.23   \n",
            "4        24.0        66135.0               1    35000.0          14.27   \n",
            "\n",
            "   loan_percent_income  cb_person_cred_hist_length  credit_score  loan_status  \\\n",
            "0                 0.49                         3.0           561            1   \n",
            "1                 0.08                         2.0           504            0   \n",
            "2                 0.44                         3.0           635            1   \n",
            "3                 0.44                         2.0           675            1   \n",
            "4                 0.53                         4.0           586            1   \n",
            "\n",
            "   person_gender  person_education  person_home_ownership  loan_intent  \\\n",
            "0              0                 4                      3            4   \n",
            "1              0                 3                      2            1   \n",
            "2              0                 3                      0            3   \n",
            "3              0                 1                      3            3   \n",
            "4              1                 4                      3            3   \n",
            "\n",
            "   previous_loan_defaults_on_file  \n",
            "0                               0  \n",
            "1                               1  \n",
            "2                               0  \n",
            "3                               0  \n",
            "4                               0  \n",
            "Epoch 1/100, Validation Accuracy: 0.8858\n",
            "Epoch 2/100, Validation Accuracy: 0.8898\n",
            "Epoch 3/100, Validation Accuracy: 0.8909\n",
            "Epoch 4/100, Validation Accuracy: 0.8898\n",
            "Epoch 5/100, Validation Accuracy: 0.8918\n",
            "Epoch 6/100, Validation Accuracy: 0.8918\n",
            "Epoch 7/100, Validation Accuracy: 0.8907\n",
            "Epoch 8/100, Validation Accuracy: 0.8918\n",
            "Epoch 9/100, Validation Accuracy: 0.8907\n",
            "Epoch 10/100, Validation Accuracy: 0.8909\n",
            "Epoch 11/100, Validation Accuracy: 0.8918\n",
            "Epoch 12/100, Validation Accuracy: 0.8916\n",
            "Epoch 13/100, Validation Accuracy: 0.8922\n",
            "Epoch 14/100, Validation Accuracy: 0.8902\n",
            "Epoch 15/100, Validation Accuracy: 0.8913\n",
            "Epoch 16/100, Validation Accuracy: 0.8916\n",
            "Epoch 17/100, Validation Accuracy: 0.8911\n",
            "Epoch 18/100, Validation Accuracy: 0.8911\n",
            "Epoch 19/100, Validation Accuracy: 0.8911\n",
            "Epoch 20/100, Validation Accuracy: 0.8898\n",
            "Epoch 21/100, Validation Accuracy: 0.8918\n",
            "Epoch 22/100, Validation Accuracy: 0.8902\n",
            "Epoch 23/100, Validation Accuracy: 0.8920\n",
            "Epoch 24/100, Validation Accuracy: 0.8898\n",
            "Epoch 25/100, Validation Accuracy: 0.8920\n",
            "Epoch 26/100, Validation Accuracy: 0.8916\n",
            "Epoch 27/100, Validation Accuracy: 0.8922\n",
            "Epoch 28/100, Validation Accuracy: 0.8911\n",
            "Epoch 29/100, Validation Accuracy: 0.8920\n",
            "Epoch 30/100, Validation Accuracy: 0.8896\n",
            "Epoch 31/100, Validation Accuracy: 0.8911\n",
            "Epoch 32/100, Validation Accuracy: 0.8929\n",
            "Epoch 33/100, Validation Accuracy: 0.8922\n",
            "Epoch 34/100, Validation Accuracy: 0.8904\n",
            "Epoch 35/100, Validation Accuracy: 0.8889\n",
            "Epoch 36/100, Validation Accuracy: 0.8900\n",
            "Epoch 37/100, Validation Accuracy: 0.8884\n",
            "Epoch 38/100, Validation Accuracy: 0.8911\n",
            "Epoch 39/100, Validation Accuracy: 0.8929\n",
            "Epoch 40/100, Validation Accuracy: 0.8898\n",
            "Epoch 41/100, Validation Accuracy: 0.8918\n",
            "Epoch 42/100, Validation Accuracy: 0.8927\n",
            "Epoch 43/100, Validation Accuracy: 0.8909\n",
            "Epoch 44/100, Validation Accuracy: 0.8893\n",
            "Epoch 45/100, Validation Accuracy: 0.8916\n",
            "Epoch 46/100, Validation Accuracy: 0.8900\n",
            "Epoch 47/100, Validation Accuracy: 0.8916\n",
            "Epoch 48/100, Validation Accuracy: 0.8900\n",
            "Epoch 49/100, Validation Accuracy: 0.8916\n",
            "Epoch 50/100, Validation Accuracy: 0.8916\n",
            "Epoch 51/100, Validation Accuracy: 0.8911\n",
            "Epoch 52/100, Validation Accuracy: 0.8916\n",
            "Epoch 53/100, Validation Accuracy: 0.8916\n",
            "Epoch 54/100, Validation Accuracy: 0.8938\n",
            "Epoch 55/100, Validation Accuracy: 0.8907\n",
            "Epoch 56/100, Validation Accuracy: 0.8896\n",
            "Epoch 57/100, Validation Accuracy: 0.8929\n",
            "Epoch 58/100, Validation Accuracy: 0.8911\n",
            "Epoch 59/100, Validation Accuracy: 0.8920\n",
            "Epoch 60/100, Validation Accuracy: 0.8913\n",
            "Epoch 61/100, Validation Accuracy: 0.8922\n",
            "Epoch 62/100, Validation Accuracy: 0.8916\n",
            "Epoch 63/100, Validation Accuracy: 0.8913\n",
            "Epoch 64/100, Validation Accuracy: 0.8913\n",
            "Epoch 65/100, Validation Accuracy: 0.8922\n",
            "Epoch 66/100, Validation Accuracy: 0.8918\n",
            "Epoch 67/100, Validation Accuracy: 0.8909\n",
            "Epoch 68/100, Validation Accuracy: 0.8924\n",
            "Epoch 69/100, Validation Accuracy: 0.8911\n",
            "Epoch 70/100, Validation Accuracy: 0.8929\n",
            "Epoch 71/100, Validation Accuracy: 0.8933\n",
            "Epoch 72/100, Validation Accuracy: 0.8916\n",
            "Epoch 73/100, Validation Accuracy: 0.8944\n",
            "Epoch 74/100, Validation Accuracy: 0.8927\n",
            "Epoch 75/100, Validation Accuracy: 0.8936\n",
            "Epoch 76/100, Validation Accuracy: 0.8929\n",
            "Epoch 77/100, Validation Accuracy: 0.8938\n",
            "Epoch 78/100, Validation Accuracy: 0.8969\n",
            "Epoch 79/100, Validation Accuracy: 0.8944\n",
            "Epoch 80/100, Validation Accuracy: 0.8942\n",
            "Epoch 81/100, Validation Accuracy: 0.8951\n",
            "Epoch 82/100, Validation Accuracy: 0.8947\n",
            "Epoch 83/100, Validation Accuracy: 0.8962\n",
            "Epoch 84/100, Validation Accuracy: 0.8960\n",
            "Epoch 85/100, Validation Accuracy: 0.8953\n",
            "Epoch 86/100, Validation Accuracy: 0.8984\n",
            "Epoch 87/100, Validation Accuracy: 0.8978\n",
            "Epoch 88/100, Validation Accuracy: 0.8989\n",
            "Epoch 89/100, Validation Accuracy: 0.8969\n",
            "Epoch 90/100, Validation Accuracy: 0.8978\n",
            "Epoch 91/100, Validation Accuracy: 0.8982\n",
            "Epoch 92/100, Validation Accuracy: 0.8991\n",
            "Epoch 93/100, Validation Accuracy: 0.8976\n",
            "Epoch 94/100, Validation Accuracy: 0.8982\n",
            "Epoch 95/100, Validation Accuracy: 0.8996\n",
            "Epoch 96/100, Validation Accuracy: 0.8987\n",
            "Epoch 97/100, Validation Accuracy: 0.8982\n",
            "Epoch 98/100, Validation Accuracy: 0.8993\n",
            "Epoch 99/100, Validation Accuracy: 0.8991\n",
            "Epoch 100/100, Validation Accuracy: 0.8984\n",
            "Accuracy: 0.8953\n",
            "Recall: 0.7173\n",
            "Precision: 0.7896\n",
            "F1 Score: 0.7517\n",
            "Confusion Matrix:\n",
            "[[3316  190]\n",
            " [ 281  713]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load and preprocess data\n",
        "loan_df = pd.read_csv('loan_data.csv')\n",
        "columns_to_encode = ['person_gender', 'person_education', 'person_home_ownership', 'loan_intent', 'previous_loan_defaults_on_file']\n",
        "label_encoder = LabelEncoder()\n",
        "loan_df_encoded = loan_df[columns_to_encode].apply(lambda col: label_encoder.fit_transform(col))\n",
        "loan_df_encoded = pd.concat([loan_df.drop(columns_to_encode, axis=1), loan_df_encoded], axis=1)\n",
        "\n",
        "print(loan_df_encoded.head())\n",
        "\n",
        "def get_train_valid_test_data(X: np.ndarray, y: np.ndarray):\n",
        "    X_trn, X_tst, y_trn, y_tst = train_test_split(X, y, train_size=0.8, random_state=42)\n",
        "    X_trn, X_vld, y_trn, y_vld = train_test_split(X_trn, y_trn, train_size=0.8, random_state=42)\n",
        "    return X_trn, y_trn, X_vld, y_vld, X_tst, y_tst\n",
        "\n",
        "# Activation functions\n",
        "class Sigmoid:\n",
        "    @staticmethod\n",
        "    def activation(z: np.ndarray) -> np.ndarray:\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    @staticmethod\n",
        "    def derivative(z: np.ndarray) -> np.ndarray:\n",
        "        sig = Sigmoid.activation(z)\n",
        "        return sig * (1 - sig)\n",
        "\n",
        "class Tanh:\n",
        "    @staticmethod\n",
        "    def activation(z: np.ndarray) -> np.ndarray:\n",
        "        return np.tanh(z)\n",
        "\n",
        "    @staticmethod\n",
        "    def derivative(z: np.ndarray) -> np.ndarray:\n",
        "        return 1 - np.tanh(z)**2\n",
        "\n",
        "def init_weights(input_size, hidden_neurons, output_neurons):\n",
        "    W1 = np.random.randn(input_size, hidden_neurons) * 0.01\n",
        "    b1 = np.zeros((1, hidden_neurons))\n",
        "    W2 = np.random.randn(hidden_neurons, output_neurons) * 0.01\n",
        "    b2 = np.zeros((1, output_neurons))\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "def get_batches(data_size, batch_size):\n",
        "    indices = np.arange(data_size)\n",
        "    np.random.shuffle(indices)\n",
        "    for start in range(0, data_size, batch_size):\n",
        "        yield indices[start:start + batch_size]\n",
        "\n",
        "def hidden_layer_grads(X, y, W1, Z1, A1, W2, Z2, A2):\n",
        "    delta2 = A2 - y.reshape(-1, 1)\n",
        "    delta1 = (delta2 @ W2.T) * Tanh.derivative(Z1)\n",
        "\n",
        "    W1_avg_grad = X.T @ delta1 / len(y)\n",
        "    b1_avg_grad = np.sum(delta1, axis=0, keepdims=True) / len(y)\n",
        "\n",
        "    return W1_avg_grad, b1_avg_grad\n",
        "\n",
        "\n",
        "def output_layer_grads(X, y, W1, Z1, A1, W2, Z2, A2):\n",
        "    delta = A2 - y.reshape(-1, 1)\n",
        "\n",
        "    W2_avg_grad = A1.T @ delta / len(y)\n",
        "    b2_avg_grad = np.sum(delta, axis=0, keepdims=True) / len(y)\n",
        "\n",
        "    return W2_avg_grad, b2_avg_grad\n",
        "\n",
        "def forward(X: np.ndarray, W1, b1, W2, b2):\n",
        "    Z1 = (X @ W1) + b1\n",
        "    A1 = Tanh.activation(Z1)\n",
        "    Z2 = (A1 @ W2) + b2\n",
        "    A2 = Sigmoid.activation(Z2)\n",
        "    return Z1, A1, Z2, A2\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, hidden_neurons, output_neurons, alpha, batch_size, epochs, seed=0):\n",
        "        self.hidden_neurons = hidden_neurons\n",
        "        self.output_neurons = output_neurons\n",
        "        self.alpha = alpha\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.seed = seed\n",
        "        self.W1, self.b1 = None, None\n",
        "        self.W2, self.b2 = None, None\n",
        "\n",
        "    def fit(self, X, y, X_vld=None, y_vld=None):\n",
        "        np.random.seed(self.seed)\n",
        "        self.W1, self.b1, self.W2, self.b2 = init_weights(X.shape[1], self.hidden_neurons, self.output_neurons)\n",
        "        for epoch in range(self.epochs):\n",
        "            for batch in get_batches(len(X), self.batch_size):\n",
        "                X_b = X[batch]\n",
        "                y_b = y[batch]\n",
        "                Z1, A1, Z2, A2 = forward(X_b, self.W1, self.b1, self.W2, self.b2)\n",
        "                W2_grad, b2_grad = output_layer_grads(X_b, y_b, self.W1, Z1, A1, self.W2, Z2, A2)\n",
        "                W1_grad, b1_grad = hidden_layer_grads(X_b, y_b, self.W1, Z1, A1, self.W2, Z2, A2)\n",
        "                self.W1 -= self.alpha * W1_grad\n",
        "                self.b1 -= self.alpha * b1_grad\n",
        "                self.W2 -= self.alpha * W2_grad\n",
        "                self.b2 -= self.alpha * b2_grad\n",
        "            if X_vld is not None and y_vld is not None:\n",
        "                y_pred = (self.predict(X_vld) >= 0.5).astype(int)\n",
        "                acc = accuracy_score(y_vld, y_pred)\n",
        "                print(f\"Epoch {epoch + 1}/{self.epochs}, Validation Accuracy: {acc:.4f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        _, _, _, A2 = forward(X, self.W1, self.b1, self.W2, self.b2)\n",
        "        return A2\n",
        "\n",
        "# Metrics\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "# Training the Model\n",
        "hidden_neurons = 128\n",
        "output_neurons = 1\n",
        "alpha = 0.01\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "\n",
        "X = loan_df_encoded.drop(columns=[\"loan_status\"]).values\n",
        "y = (loan_df_encoded[\"loan_status\"].values > 0).astype(int)\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=0.8, random_state=42)\n",
        "X_vld, X_test, y_vld, y_test = train_test_split(X_temp, y_temp, train_size=0.5, random_state=42)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_vld = scaler.transform(X_vld)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "nn_model = NeuralNetwork(hidden_neurons, output_neurons, alpha, batch_size, epochs)\n",
        "nn_model.fit(X_train, y_train, X_vld=X_vld, y_vld=y_vld)\n",
        "\n",
        "y_test_pred = (nn_model.predict(X_test) >= 0.5).astype(int)\n",
        "evaluate_model(y_test, y_test_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "loan_df = pd.read_csv('loan_data.csv')\n",
        "label_encoders = {}\n",
        "\n",
        "df_columns = loan_df.select_dtypes(include=['object']).columns\n",
        "for column in df_columns:\n",
        "    le = LabelEncoder()\n",
        "    loan_df[column] = le.fit_transform(loan_df[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "if loan_df['loan_status'].isnull().any():\n",
        "    print(\"Missing values found in 'loan_status'. Handling them by dropping rows.\")\n",
        "    loan_df = loan_df.dropna(subset=['loan_status'])\n",
        "\n",
        "X = loan_df.drop(columns=['loan_status']).values\n",
        "y = loan_df['loan_status'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, zero_division=1)\n",
        "recall = recall_score(y_test, y_pred, zero_division=1)\n",
        "f1 = f1_score(y_test, y_pred, zero_division=1)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kYQj52t6-Q4",
        "outputId": "3e670f83-ed5b-4a4f-b03b-5d1b531d0055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8918888888888888\n",
            "Precision: 0.7856749311294766\n",
            "Recall: 0.709452736318408\n",
            "F1 Score: 0.7456209150326797\n"
          ]
        }
      ]
    }
  ]
}